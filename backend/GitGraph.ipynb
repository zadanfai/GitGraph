{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtZGso-hhlBJ",
        "outputId": "dd637999-d097-417b-8886-1dd3c81caeb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_scatter-2.1.2%2Bpt23cu121-cp311-cp311-linux_x86_64.whl (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m114.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_sparse-0.6.18%2Bpt23cu121-cp311-cp311-linux_x86_64.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m106.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_cluster-1.6.3%2Bpt23cu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m103.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_spline_conv-1.2.2%2Bpt23cu121-cp311-cp311-linux_x86_64.whl (950 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.4/950.4 kB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.15)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.5.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.6.15)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m108.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m112.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv, torch-scatter, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, torch-sparse, torch-cluster, nvidia-cusparse-cu12, nvidia-cudnn-cu12, torch-geometric, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torch-cluster-1.6.3+pt23cu121 torch-geometric-2.6.1 torch-scatter-2.1.2+pt23cu121 torch-sparse-0.6.18+pt23cu121 torch-spline-conv-1.2.2+pt23cu121\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas scikit-learn torch torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cu121.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch_geometric.data import HeteroData\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "\n",
        "users_df = pd.read_csv('users.csv')\n",
        "repos_df = pd.read_csv('repos.csv')\n",
        "stars_df = pd.read_csv('stars.csv')\n",
        "\n",
        "print(f'Loaded {len(users_df)} user, {len(repos_df)} repos, and {len(stars_df)} relationships')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqrSbY6IiOuF",
        "outputId": "fb3e9d6a-4d4a-4e1b-fd1b-99b9f287a504"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 2617 user, 100 repos, and 2693 relationships\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(users_df, repos_df):\n",
        "\n",
        "  # Missing value\n",
        "  users_df['bio'].fillna('', inplace=True)\n",
        "  repos_df['description'].fillna('', inplace=True)\n",
        "  repos_df['language'].fillna('', inplace=True)\n",
        "  repos_df['stargazers_count'].fillna(0, inplace=True)\n",
        "\n",
        "  # TF-IDF\n",
        "  all_text = pd.concat([users_df['bio'], repos_df['description'], repos_df['language']], ignore_index=True)\n",
        "  vectorizer = TfidfVectorizer(max_features=128)\n",
        "  vectorizer.fit(all_text)\n",
        "\n",
        "  user_bio_features = vectorizer.transform(users_df['bio']).toarray()\n",
        "  repo_desc_features = vectorizer.transform(repos_df['description']).toarray()\n",
        "  repo_lang_features = vectorizer.transform(repos_df['language']).toarray()\n",
        "\n",
        "  repo_stars = repos_df[['stargazers_count']].to_numpy(dtype=np.float32)\n",
        "  repo_features = np.concatenate([repo_desc_features, repo_lang_features, repo_stars], axis=1)\n",
        "\n",
        "  return user_bio_features, repo_features, vectorizer"
      ],
      "metadata": {
        "id": "KAnSNZrUjHO-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Preprocessing data...')\n",
        "user_features, repos_features, vectorizer = preprocess_data(users_df, repos_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKsW7DjYmgli",
        "outputId": "19e15589-551e-463f-8aa8-7ae9c5399a1f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-20-3894596216.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  users_df['bio'].fillna('', inplace=True)\n",
            "/tmp/ipython-input-20-3894596216.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  repos_df['description'].fillna('', inplace=True)\n",
            "/tmp/ipython-input-20-3894596216.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  repos_df['language'].fillna('', inplace=True)\n",
            "/tmp/ipython-input-20-3894596216.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  repos_df['stargazers_count'].fillna(0, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_hetero_object(users_df, repos_df, stars_df, user_features, repo_features):\n",
        "  data = HeteroData()\n",
        "\n",
        "  data['user'].x = torch.tensor(user_features, dtype=torch.float32)\n",
        "  data['repo'].x = torch.tensor(repo_features, dtype=torch.float32)\n",
        "\n",
        "  # Mapping from unique IDs (login/fullname)\n",
        "  user_map = {login: i for i, login in enumerate(users_df['login'])}\n",
        "  repo_map = {name: i for i, name in enumerate(repos_df['full_name'])}\n",
        "\n",
        "  # Ubah source index dri edge ke index integer\n",
        "  source_indices = torch.tensor([user_map[login] for login in stars_df['source']])\n",
        "  target_indices = torch.tensor([repo_map[name] for name in stars_df['target']])\n",
        "\n",
        "  edge_index = torch.stack([source_indices, target_indices], dim=0)\n",
        "\n",
        "  # Add informasi edge ke objek graf\n",
        "  # format (source_node_type, edge_type, target_node_type)\n",
        "  data['user', 'stars', 'repo'].edge_index = edge_index\n",
        "\n",
        "  return data, user_map, repo_map"
      ],
      "metadata": {
        "id": "7aOojzgsmtP9"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Creating HeteroData object...')\n",
        "graphdata, user_map, repo_map = create_hetero_object(users_df, repos_df, stars_df, user_features, repos_features)\n",
        "\n",
        "print(\"Pytorch Geometric Graph Object succesfully created...\")\n",
        "print(\"Berikut adalah struktur graf:\")\n",
        "print(graphdata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YM2uL2CuoOjV",
        "outputId": "25ea7a24-53a1-4223-f672-9ec1952dad44"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating HeteroData object...\n",
            "Pytorch Geometric Graph Object succesfully created...\n",
            "Berikut adalah struktur graf:\n",
            "HeteroData(\n",
            "  user={ x=[2617, 128] },\n",
            "  repo={ x=[100, 257] },\n",
            "  (user, stars, repo)={ edge_index=[2, 2693] }\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import SAGEConv, HeteroConv\n",
        "\n",
        "class HeteroGNN(torch.nn.Module):\n",
        "  def __init__(self, hidden_channels, out_channels):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv1 = HeteroConv({\n",
        "        ('user', 'stars', 'repo'): SAGEConv((-1, -1), hidden_channels),\n",
        "        ('repo', 'rev_stars', 'user'): SAGEConv((-1, -1), hidden_channels),\n",
        "    }, aggr='sum')\n",
        "\n",
        "    self.conv2 = HeteroConv({\n",
        "        ('user', 'stars', 'repo'): SAGEConv((-1, -1), out_channels),\n",
        "        ('repo', 'rev_stars', 'user'): SAGEConv((-1, -1), out_channels),\n",
        "    }, aggr='sum')\n",
        "\n",
        "  def forward(self, x_dict, edge_index_dict):\n",
        "    \"\"\"\n",
        "    Mendefinisikan feed forward model\n",
        "    x_dict: Dictionary berisi fitur-fitur node\n",
        "    edge_index_dict: Dictionary berisi konektvitas edge\n",
        "    \"\"\"\n",
        "\n",
        "    hidden_embeds = self.conv1(x_dict, edge_index_dict)\n",
        "    final_embeds = {key: x.relu() for key, x in hidden_embeds.items()}\n",
        "\n",
        "    final_embeds = self.conv2(hidden_embeds, edge_index_dict)\n",
        "\n",
        "    return final_embeds\n",
        "\n",
        "\n",
        "\n",
        "# --- Verifikasi Model ---\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "\n",
        "transform = T.ToUndirected()\n",
        "graph_data_undirected = transform(graphdata)\n",
        "\n",
        "print('Struktur Graph setelah ditambahkan undirected edge:')\n",
        "print(graph_data_undirected)\n",
        "\n",
        "\n",
        "model = HeteroGNN(hidden_channels=64, out_channels=32)\n",
        "\n",
        "print(\"\\nArsitektur Model GNN:\")\n",
        "print(model)\n",
        "\n",
        "with torch.no_grad():\n",
        "  output_embeddings = model(graph_data_undirected.x_dict, graph_data_undirected.edge_index_dict)\n",
        "\n",
        "print(\"\\nOutput model (dictionary of embeddings):\")\n",
        "for node_type, embeddings in output_embeddings.items():\n",
        "  print(f\"  - Tipe Node: '{node_type}', Ukuran Embedding: {embeddings.shape}\")"
      ],
      "metadata": {
        "id": "qTcKVOf6orwF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c312095-3bcd-4b68-9565-130ffed35c10"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Struktur Graph setelah ditambahkan undirected edge:\n",
            "HeteroData(\n",
            "  user={ x=[2617, 128] },\n",
            "  repo={ x=[100, 257] },\n",
            "  (user, stars, repo)={ edge_index=[2, 2693] },\n",
            "  (repo, rev_stars, user)={ edge_index=[2, 2693] }\n",
            ")\n",
            "\n",
            "Arsitektur Model GNN:\n",
            "HeteroGNN(\n",
            "  (conv1): HeteroConv(num_relations=2)\n",
            "  (conv2): HeteroConv(num_relations=2)\n",
            ")\n",
            "\n",
            "Output model (dictionary of embeddings):\n",
            "  - Tipe Node: 'repo', Ukuran Embedding: torch.Size([100, 32])\n",
            "  - Tipe Node: 'user', Ukuran Embedding: torch.Size([2617, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import neg\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import torch_geometric.transforms as T\n",
        "\n",
        "\n",
        "# --- 1. Mempersiapkan Data untuk Link Prediction ---\n",
        "# Kita perlu membagi edge kita menjadi set train/validation/test.\n",
        "# PyG menyediakan transform yang sangat berguna untuk ini.\n",
        "# T.RandomLinkSplit akan:\n",
        "#  - Membagi edge 'stars' menjadi 3 set.\n",
        "#  - Membuat sampel edge negatif (link yang tidak ada) secara otomatis untuk setiap set.\n",
        "#  - Menghapus edge validation & test dari graf utama agar model tidak \"curang\".\n",
        "\n",
        "link_split_transform = T.RandomLinkSplit(\n",
        "    num_val=0.1,\n",
        "    num_test=0.1,\n",
        "    is_undirected=True,\n",
        "    split_labels=True,\n",
        "    add_negative_train_samples=True,\n",
        "    edge_types=[('user', 'stars', 'repo')],\n",
        "    rev_edge_types=[('repo', 'rev_stars', 'user')],\n",
        ")\n",
        "\n",
        "train_data, val_data, test_data = link_split_transform(graph_data_undirected)\n",
        "\n",
        "print(\"\\n--- Data setelah di-split untuk Link Prediction ---\")\n",
        "print(\"Data Latih (Train):\", train_data)\n",
        "print(\"Data Validasi (Val):\", val_data)\n",
        "print(\"Data Uji (Test):\", test_data)\n",
        "\n",
        "\n",
        "# --- 2. Mendefinisikan Model Akhir dengan Decoder ---\n",
        "# Model ini akan membungkus GNN (encoder) dan menambahkan logika decoder.\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "  def __init__(self, hidden_channels, out_channels):\n",
        "    super().__init__()\n",
        "    self.encoder = HeteroGNN(hidden_channels, out_channels)\n",
        "\n",
        "  def forward(self, data):\n",
        "    embeddings = self.encoder(data.x_dict, data.edge_index_dict)\n",
        "    return embeddings\n",
        "\n",
        "  def decode(self, embeddings, edge_label_index):\n",
        "    user_embeds = embeddings['user'][edge_label_index[0]]\n",
        "    repo_embeds = embeddings['repo'][edge_label_index[1]]\n",
        "\n",
        "    preds = (user_embeds * repo_embeds).sum(dim=-1)\n",
        "    return preds\n",
        "\n",
        "  def decode_all(self, embeddings):\n",
        "    preds = torch.matmul(embeddings['user'], embeddings['repo'].t())\n",
        "    return preds\n",
        "\n",
        "\n",
        "# --- 3. Training Loop ---\n",
        "\n",
        "model = Model(hidden_channels=64, out_channels=32)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "def train():\n",
        "  model.train()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # Dapetin embedding dri GNN\n",
        "  embeddings =  model.encoder(train_data.x_dict, train_data.edge_index_dict)\n",
        "\n",
        "  # Gabungin edge (+/-) manual\n",
        "  edge_store = train_data['user', 'stars', 'repo']\n",
        "  pos_index = edge_store.pos_edge_label_index\n",
        "  neg_index = edge_store.neg_edge_label_index\n",
        "\n",
        "  # Gabungin index dari edge (+/-)\n",
        "  edge_label_index = torch.cat([pos_index, neg_index], dim=1)\n",
        "\n",
        "  # Gabungin label (1 buat positif, 0 buat negatif)\n",
        "  pos_label = edge_store.pos_edge_label\n",
        "  neg_label = edge_store.neg_edge_label\n",
        "  edge_label = torch.cat([pos_label, neg_label], dim=0)\n",
        "\n",
        "  # Dapetin prediksi dari decoder\n",
        "  preds = model.decode(embeddings, edge_label_index)\n",
        "\n",
        "  # Loss\n",
        "  loss = F.binary_cross_entropy_with_logits(preds, edge_label)\n",
        "\n",
        "  # backpropagation\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  return float(loss)\n",
        "\n",
        "\n",
        "# --- 4. Evaluation Loop ---\n",
        "@torch.no_grad()\n",
        "def test(data):\n",
        "  model.eval()\n",
        "  embeddings = model.encoder(data.x_dict, data.edge_index_dict)\n",
        "\n",
        "  edge_store = data['user', 'stars', 'repo']\n",
        "  pos_index = edge_store.pos_edge_label_index\n",
        "  neg_index = edge_store.neg_edge_label_index\n",
        "  edge_label_index = torch.cat([pos_index, neg_index], dim=1)\n",
        "\n",
        "  pos_label = edge_store.pos_edge_label\n",
        "  neg_label = edge_store.neg_edge_label\n",
        "  edge_label = torch.cat([pos_label, neg_label], dim=0)\n",
        "\n",
        "  preds = model.decode(embeddings, edge_label_index)\n",
        "\n",
        "  # AUC\n",
        "  return roc_auc_score(edge_label.cpu().numpy(), preds.cpu().numpy())\n",
        "\n",
        "\n",
        "# --- 5. Jalankan Pelatihan ---\n",
        "print(\"\\n--- Training Model ---\")\n",
        "for epoch in range(1, 201):\n",
        "  loss = train()\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    train_auc = test(train_data)\n",
        "    val_auc = test(val_data)\n",
        "    test_auc = test(test_data)\n",
        "    print(f\"Epoch: {epoch:03d}, Loss: {loss:.4f}, Train AUC: {train_auc:.4f}, Val AUC {val_auc:.4f}, Test AUC: {test_auc:.4f}\")\n",
        "\n",
        "print(\"\\n--- Training Done ---\")\n",
        "final_test_auc = test(test_data)\n",
        "print(f\"Skor AUC final pada data uji: {final_test_auc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUCoX2pIkvdx",
        "outputId": "f17560a0-b8ee-49a7-a037-15374b5b949b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Data setelah di-split untuk Link Prediction ---\n",
            "Data Latih (Train): HeteroData(\n",
            "  user={ x=[2617, 128] },\n",
            "  repo={ x=[100, 257] },\n",
            "  (user, stars, repo)={\n",
            "    edge_index=[2, 2155],\n",
            "    pos_edge_label=[2155],\n",
            "    pos_edge_label_index=[2, 2155],\n",
            "    neg_edge_label=[2155],\n",
            "    neg_edge_label_index=[2, 2155],\n",
            "  },\n",
            "  (repo, rev_stars, user)={ edge_index=[2, 2155] }\n",
            ")\n",
            "Data Validasi (Val): HeteroData(\n",
            "  user={ x=[2617, 128] },\n",
            "  repo={ x=[100, 257] },\n",
            "  (user, stars, repo)={\n",
            "    edge_index=[2, 2155],\n",
            "    pos_edge_label=[269],\n",
            "    pos_edge_label_index=[2, 269],\n",
            "    neg_edge_label=[269],\n",
            "    neg_edge_label_index=[2, 269],\n",
            "  },\n",
            "  (repo, rev_stars, user)={ edge_index=[2, 2155] }\n",
            ")\n",
            "Data Uji (Test): HeteroData(\n",
            "  user={ x=[2617, 128] },\n",
            "  repo={ x=[100, 257] },\n",
            "  (user, stars, repo)={\n",
            "    edge_index=[2, 2424],\n",
            "    pos_edge_label=[269],\n",
            "    pos_edge_label_index=[2, 269],\n",
            "    neg_edge_label=[269],\n",
            "    neg_edge_label_index=[2, 269],\n",
            "  },\n",
            "  (repo, rev_stars, user)={ edge_index=[2, 2424] }\n",
            ")\n",
            "\n",
            "--- Training Model ---\n",
            "Epoch: 010, Loss: 759513.3750, Train AUC: 0.6231, Val AUC 0.1666, Test AUC: 0.0838\n",
            "Epoch: 020, Loss: 640940.2500, Train AUC: 0.6321, Val AUC 0.1895, Test AUC: 0.1166\n",
            "Epoch: 030, Loss: 15937.0449, Train AUC: 0.3383, Val AUC 0.2514, Test AUC: 0.2554\n",
            "Epoch: 040, Loss: 219425.8906, Train AUC: 0.5657, Val AUC 0.2137, Test AUC: 0.1930\n",
            "Epoch: 050, Loss: 12131.1123, Train AUC: 0.3245, Val AUC 0.5569, Test AUC: 0.5935\n",
            "Epoch: 060, Loss: 42416.1250, Train AUC: 0.5992, Val AUC 0.1926, Test AUC: 0.1395\n",
            "Epoch: 070, Loss: 6411.6289, Train AUC: 0.7099, Val AUC 0.2960, Test AUC: 0.2204\n",
            "Epoch: 080, Loss: 25311.5586, Train AUC: 0.6492, Val AUC 0.2027, Test AUC: 0.1425\n",
            "Epoch: 090, Loss: 301.2462, Train AUC: 0.4984, Val AUC 0.6810, Test AUC: 0.6596\n",
            "Epoch: 100, Loss: 6684.1401, Train AUC: 0.6229, Val AUC 0.1653, Test AUC: 0.0997\n",
            "Epoch: 110, Loss: 461.2666, Train AUC: 0.7054, Val AUC 0.6280, Test AUC: 0.5948\n",
            "Epoch: 120, Loss: 954.5260, Train AUC: 0.7199, Val AUC 0.5738, Test AUC: 0.5264\n",
            "Epoch: 130, Loss: 6028.9502, Train AUC: 0.7026, Val AUC 0.2910, Test AUC: 0.2236\n",
            "Epoch: 140, Loss: 234.0671, Train AUC: 0.6538, Val AUC 0.1753, Test AUC: 0.1100\n",
            "Epoch: 150, Loss: 1218.3075, Train AUC: 0.6699, Val AUC 0.2456, Test AUC: 0.1887\n",
            "Epoch: 160, Loss: 241.1116, Train AUC: 0.7066, Val AUC 0.6254, Test AUC: 0.5921\n",
            "Epoch: 170, Loss: 171.6772, Train AUC: 0.7166, Val AUC 0.6173, Test AUC: 0.5963\n",
            "Epoch: 180, Loss: 2097.4294, Train AUC: 0.7299, Val AUC 0.3378, Test AUC: 0.2733\n",
            "Epoch: 190, Loss: 221.1447, Train AUC: 0.7213, Val AUC 0.2709, Test AUC: 0.2052\n",
            "Epoch: 200, Loss: 344.7759, Train AUC: 0.7340, Val AUC 0.3594, Test AUC: 0.3016\n",
            "\n",
            "--- Training Done ---\n",
            "Skor AUC final pada data uji: 0.3016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "SAVE_PATH = os.path.join('./', \"saved_model_assets\")\n",
        "os.makedirs(SAVE_PATH, exist_ok=True)\n",
        "\n",
        "print(f\"Aset akan disimpan di: {SAVE_PATH}\")\n",
        "\n",
        "model_save_path = os.path.join(SAVE_PATH, \"gnn_model_state.pth\")\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "print(f\"Model state dictionary berhasil disimpan ke: {model_save_path}\")\n",
        "\n",
        "vectorizer_save_path = os.path.join(SAVE_PATH, \"tfidf_vectorizer.pkl\")\n",
        "with open(vectorizer_save_path, 'wb') as f:\n",
        "  pickle.dump(vectorizer, f)\n",
        "print(f'TF-IDF Vectorizer berhasil diisimpan ke: {vectorizer_save_path}')\n",
        "\n",
        "user_map_path = os.path.join(SAVE_PATH, \"user_map.pkl\")\n",
        "with open(user_map_path, 'wb') as f:\n",
        "    pickle.dump(user_map, f)\n",
        "print(f\"User map berhasil disimpan ke: {user_map_path}\")\n",
        "\n",
        "repo_map_path = os.path.join(SAVE_PATH, \"repo_map.pkl\")\n",
        "with open(repo_map_path, 'wb') as f:\n",
        "    pickle.dump(repo_map, f)\n",
        "print(f\"Repo map berhasil disimpan ke: {repo_map_path}\")\n",
        "\n",
        "print(\"\\n--- Semua aset model berhasil disimpan! ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_FtMKY7sXrU",
        "outputId": "4e665ea1-31d5-4e8b-e02e-b50b3b3e83d5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aset akan disimpan di: ./saved_model_assets\n",
            "Model state dictionary berhasil disimpan ke: ./saved_model_assets/gnn_model_state.pth\n",
            "TF-IDF Vectorizer berhasil diisimpan ke: ./saved_model_assets/tfidf_vectorizer.pkl\n",
            "User map berhasil disimpan ke: ./saved_model_assets/user_map.pkl\n",
            "Repo map berhasil disimpan ke: ./saved_model_assets/repo_map.pkl\n",
            "\n",
            "--- Semua aset model berhasil disimpan! ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C1zCCgc4FYTD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}